<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="a2xhtml.xslt"?>
<!-- $Id$ -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"
  xmlns:a="http://pom.clacbec.net/xmlns/a">
  <head>
    <meta http-equiv="Content-Type" content="text/xml+html; charset=UTF-8"/>
    <title>The Urakawa Application First Iteration Requirements</title>
    <meta name="author"
    content="Julien Quint &lt;julien@daisy-for-all.org&gt;"/>
    <meta name="copyright" content="DAISY Consortium, CWI, INRIA, NRCD"/>
    <meta name="description" content="Proposal for the Urakawa Application"/>
    <style type="text/css">
      body { background-color: white; color: black; margin: 3em; text-align:
        justify; font-family: Georgia, serif; font-size: 12pt }
      h1, h2, h3 { font-family: "Gill Sans", sans-serif; color: #04a }
      h1 { font-size: 150%; letter-spacing: .2em; text-align: center }
      h2 { font-size: 120%; }
      h3 { font-size: 100%; }
      address { font-style: normal; text-align: center }
      .in { text-indent: 1em }
      code { font-size: 90% }
      a { color: #009; font-weight: bold; text-decoration: none }
      p.back { font-size: small; text-align: right; }
      dt { font-weight: bold; }
    </style>
  </head>

  <body>

    <h1>The Urakawa Application First Iteration Requirements</h1>
    <address>Julien Quint <a:email addr="julien@daisy-for-all.org"/><br/>
      Markus Gylling <a:email addr="markus.gylling@tpb.se"/><br/>
      Second draft, $Date$</address>

    <p>This document details the requirements for the first iteration of the
    Urakawa Application, currently code-named <acronym
      title="Happy Fun Daisy Time">HFDT</acronym>, to be built on top of the
    first iteration of the Urakawa Toolkit. The goal is not only to test and
    showcase the toolkit, but also to deliver a real-world Daisy Z production
    tool.<a:quick-toc/></p>

    <a:section id="inclexcl">
      <h2>Inclusions and Exclusions</h2>
      <p>This section gives an overview of items that are required for the
        first iteration, and those that have been pushed back to the next
        iteration(s). They cover the items listed during the Cannes F2F in
        March 2006; some changes have been made to this list in the
        meantime (<em>e.g.</em> incl-16 is now excluded.)</p>

      <a:section>
        <h3>Inclusions</h3>
        <dl>

          <dt>incl-1: XUK import;</dt>
          <dt>incl-2: XUK export.</dt>
          <dt>incl-15: an actual save menu item/button.</dt>
          <dd><a href="http://www.daisy.org/projects/dmfc/"><acronym
                title="Daisy Multi Format Converter">DMFC</acronym></a> is used
            to transform DTBs and DTBook files to the Urakawa XUK file format,
            and from XUK to DTB. The GUI-version of DMFC should be available
            in time for HFDT to use.</dd>

          <dt>incl-20: application manual in XHTML format.</dt>
          <dd>Ideally, a full-text/full-audio DTB would be better, or even a
            DTB document, but for the first iteration, XHTML will do. Even
            though the development team may make a first draft, this document
            should be edited by a writer rather than a developer.</dd>

          <dt>incl-21: i18n: translatability of text prompts.</dt>
          <dd>For this item we can use the framework currently developed for
            AMIS.</dd>

          <dt>incl-4: live audio recording;</dt>
          <dt>incl-5: audio editing facilities;</dt>
          <dt>incl-6: accessible VU and peak meters;</dt>
          <dt>incl-11: phrase detection on recorded audio data;</dt>
          <dt>incl-12: ability to merge a set of badly detected phrases and
            redo with other parameters;</dt>
          <dt>incl-13: set parameters for phrase detection;</dt>
          <dt>incl-14: trim start and end of selected audio without physical
            changes;</dt>
          <dt>incl-17: only one recording mode: &#x201c;append;&#x201d;</dt>
          <dt>incl-18: ability to add markers while recording;</dt>
          <dt>incl-19: only RIFF WAVE format of audio.</dt>
          <dd>See <a:ref label="audioreqs"/> for details. This iteration only
            requires support for RIFF WAVE format but any uncompressed audio
            format required by Daisy can probably be easily supported.</dd>

          <dt>incl-7: discard unreferenced media assets only on user
            request;</dt>
          <dt>incl-8: XUK format shall be able to include unreferenced media
            assets.</dt>
          <dd>See <a:ref label="assetreqs"/> for details.</dd>

          <dt>incl-3: NCX authoring and editing facilities;</dt>
          <dt>incl-9: support skippable and escapable structures;</dt>
          <dt>incl-10: support for NCX-Only DTBs.</dt>
          <dd>See <a:ref label="ncxreqs"/> for details. Support for full (or
            partial) text DTB is pushed back to the next iteration to focus on
            the three main components of the first iteration (sound editing,
            asset management, and NCX editing.)</dd>
        </dl>
      </a:section>

      <a:section>
        <h3>Exclusions</h3>
        <dl>

          <dt>incl-16: synthesized speech for full text books.</dt>
          <dd>This is pushed to next iteration as we very probably won't
            support full text in the first iteration.</dd>

          <dt>excl-1: DTBook editing.</dt>
          <dd>The first iteration will not support text, so this is not an issue
            yet. However, when text is introduced, we may want to be extremely
            conservative (even to the point of forbidding editing of any kind,
            even for a minor typo.)</dd>

          <dt>excl-2: self-voicing.</dt>
          <dd>We will rely on screen reader abilities.</dd>

          <dt>excl-3: DTB annotations (bookmarks, notes.)</dt>
          <dt>excl-4: media asset annotations.</dt>
          <dt>excl-5: full text browser display.</dt>
          <dt>excl-6: resource file authoring.</dt>
          <dt>excl-7: autosave.</dt>
          <dt>excl-8: add text to existing audio (ATAU.)</dt>
          <dt>excl-9: plugin support.</dt>
          <dt>excl-10: customizable colors and scalable widgets.</dt>

          <dt>excl-11: all Daisy audio file formats, especially compressed
            audio.</dt>
          <dd>There may be patent issues with some file formats, such as
            MP3.</dd>

          <dt>excl-12: QA player.</dt>
          <dd><a href="http://amis.sf.net/">Amis</a> will probably be the QA
            player. We will need better inclusion of DMFC and bookmarks support
            so that the author can annotate the book during QA playing and
            easily find places where corrections need to be made.</dd>

          <dt>excl-13: context sensitive help (pointing to the help DTB.)</dt>
        </dl>
      </a:section>

    </a:section>

    <a:section id="audioreqs">
      <h2>Audio Editor Requirements</h2>
      <pre>  Two widgets:
   LiveAudioRecordingDialog
   AudioEditEngine
   
  Functional Requirements on LiveAudioRecordingDialog (Avneesh and Sumans deliverable)
     1. Recording of audiofiles     
     should AudioEngine read core tree directly, or just get playback commands?
     should AudioEngine be able populate the core tree directly?
     tentative answer; AudioEngine is not aware of core tree, only recieves play and record commands     
     also able to read asset manager files
     Vu-meter (might be a third widget)
     set options
         
  Functional Requirements on AudioEditEngine (Avneesh and Sumans deliverable)
   Should be a .net "custom control"
   Must have an assettManager registered with it (to which low level cut/copy/paste is delegated)
   has internal command pattern impl for selections/markers etc
         
   1. Playback of audiofiles
                       
   2. Markers: 
     points to a point in time (unknown whether represented in core tree)
     support querying about exact time position and what file
     support querying about index on current wave
     can be moved around freely 
     can have a name   
     should be lockable and if unlocked easy to move     
     insert manually or automatically while recording (passed an event from GUI)
   
   3. Selection:
     a span in time (begin and end)
     support query of start, end and length
     used for cut copy paste
     always contiguous (start and end in same file)
     only one active at a given time in the widget
     able to turn selection into phrase
     able to select everyting
     unselect
     reselect (by undo/redo)      
           
   4. Phrases: 
     AudioEngine can make phrase detection on a selection
     would mark phrases on the audio, including leading silence for the
     first one, and trailing silence for all
     phrase is much like a selection;
     a span in time (begin and end)
     support query of start, end and length
     used for cut copy paste
     always contiguous (start and end in same file)
     -->but also: can be named, can be more than one
     and have more information because they are linked
     to text nodes... they are first class citizens in 
     the core tree
     resistant to change (as compared to selection)
     able to lock, unlock
     when unlocked able to shrink and extend and move around
     special behavior:
      if move a phrase next to another
      must not overlap
  
   5. Visualization
   AudioEngine is also responsible for visualization: includes
     waveform display 
       zoom (in time, in amplitude, in, out, fit everything)
       scroll while play
     markers 
       small label, small handle to move or lock
       accessibilized; make indexes or a special play mode which is 'move marker'       
     selection
       highlight
       extend or shrink
       make a selection from two consecutive markers
       or a selection and preceeding or following marker
       non-visually - there is no selection; instead using indexes and phrases       
     region (which equals smil:audioclip/'phrase' only when committed to tree)
       framed(look like a box) and/or highlighted (different highlite than selections); 
       small label and handle to move (whole, start, end) and lock
       (goal of region is eventually to become a phrase)
     
     ability to tell whether a phrase is synchronized or not (ie comitted to tree or not)
  
   6. Editing operations
     Low level operations: 
       physical operations on selection in audio files:
       cut - cuts and puts in clipboard
       copy - puts selection in clipboard 
       delete - deletes selection, doesnt put in clipboard
       paste - pastes on cursor position, inserts (=doesnt replace) 
                     
       noise removal (not iter1)
       normalization (not iter1, unless media framework gives it for free)
       amplitude modification (not iter1, unless media framework gives it for free)
     
     High level operations: selections etc
       phrase detection</pre>
    </a:section>

    <a:section id="assetreqs">
      <h2>Asset Manager Jr. Requirements</h2>
    </a:section>

    <a:section id="ncxreqs">
      <h2>NCX Editor Requirements</h2>
    </a:section>

  </body>
</html>
