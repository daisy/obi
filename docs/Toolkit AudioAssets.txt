Document describing toolkit asset manager w.r.t. to Obi's native asset manager 
Document also contains features required by Application team in toolkit AssetManager.
First Draft by Avneesh on May 31, 2007


The toolkit contains two implementations of AudioAssets:

1. ExternalAudioMedia
2.  AudioMediaData


ExternalAudioMedia deals with direct access to physical files. while AudioMediaData deals with virtual concept similar to Obi's native  AudioMediaAsset and AssetManager. 

Discription of ExternalAudioMedia:
ExternalAudioMedia represents a part of an Audio file being represented in ExternalAudioMedia with its src, BeginTime and EndTime.
This class can be used directly for filling Audio information in smil files as smil also provide src, clip begin and clip end information.
This is not of direct use in Obi as we need to do virtual Audio editing.


Discription of AudioMediaData:
AudioMediaData is similar to Obi's native AudioMediaAsset class.
AudioMediaData is abstract and implemented in WavAudioMediaData class for raw wave format.
Discription of WavAudioMediaData
WavAudioMediaData mainly contains a reference of Manager with 
another protected class named WavClip.
WavClip class cannot be accessed directly from outside. It basically represents a part of physical wave file with  following members.
- Clip Start  time w.r.t. File.
- Clip end time w.r.t. file.
- IDataProvider   implemented in  FileDataProvider.
which further basically contains the src information of audio file on disk and media mime type information.

The WaveAudioMediaData class contains an  list of WavClips as
List<WavClip> mWavClips 
WavClips in this list are arranged according of their play order.

WaveAudioMediaData has following public functions for Audio editing
tf1. Stream getAudioData(ITime clipBegin, ITime clipEnd)
tf2. void appendAudioData(Stream pcmData, ITimeDelta duration)
tf3. insertAudioData(Stream pcmData, ITime insertPoint, ITimeDelta duration)
tf4. void replaceAudioData(Stream pcmData, ITime replacePoint, ITimeDelta duration)
tf5. void removeAudio(ITime clipBegin, ITime clipEnd)
tf6. void delete()

Audio Editing is mostly stream based in WavAudioMediaData which is good as it do not break encapsulation when we need to dig out binary data from audio files but depending only on streams makes things complex as many times  during audio editing, we are dealing with AudioMediaData objects and not with bytes from files.

Streams are of great use for low level audio stuff like playing, phrase detector and recording but for all other audio edits we need audio editing on higher layer i.e. AudioMediaData and WavAudioMediaData layer.


Starting the problem discription from AudioRecorder with proposed solutions from Application team:

1. Problem description in audio recorder:
Existing code flow is as follows:
An AudioMediaAsset is passed to AudioRecorder start recording function.
AudioRecorder creates a physical file with audio format matching format of AudioAsset passed to start recording function.
After Recorder has finished, the wave file just created by AudioRecorder is encapsulated in an audioClip and appended to ClipList maintained by AudioMediaAsset.


We can not go in same way in toolkit AudioMediaData as Clip class is protected which is a good thing from our point of view as this implementation should be hidden from Application developer.
It is proposed to use any one of following:
1.1. Toolkit AudioMediaData should have afunction which recieves a audio file path or its equivalent as parameter and returns PCM Stream.
This PCM stream can be then used in above listed functions from tf2 to tf4 for including just recorded data in AudioMediaData which was passed to start recording function.
It is recommended to have this function as static such that it is not mandatory to create an instance of AudioMediaData  for getting a stream out of File.
1.2. Have functions to Append,  insert and replace  audio data directly from audio files. i.e.
Overloads for functions tf2 to tf4 with file path or its equivalent as input parameter instead of stream.



2. Importing audio file:
Current code flow is follows:
Audio External wave file is encapsulated in AudioClip while deriving Clip format information from wave file.
A new  AudioMediaAsset is created containing this AudioClip. The format of this AudioMediaAsset is again derived from  just created AudioClip.

Again WavClip class in toolkit is protected so we cannot go like this.

It is proposed to use any one of  following:
2.1. Have a funtion in toolkit to import audio files which takes file path or its equivalent as parameter and return AudioMediaData.
2.2. Use the function described. in 1.1. to get a stream from external wave file, 
and do following work in Obi:
- create a new AudioMediaData with no audio 
- use stream created from external file as parameter to AppendAudio function listed as tf2 in order to fill this AudioMediaData with audio. 



3. Split and Merge:
Both of these functions do not need to access underlying binary data in audio files and currently  operate at layer 
of AudioMediaAsset in Obi.
It is proposed to have functions in toolkit AudioMediaData to accomplish splitting and merging at layer of AudioMediaData or WavAudioMediaData as follows:
3.1. A split function which takes AudioMediaData as parameter and returns a new AudioMediaData while modifying end point of original AudioMediaData.
3.2. A merge function which takes AudioMediaData as parameter and returns a combined  AudioMediaData.


4. Phrase Detection:
Code flow:
underlying binary data from clips is processed to mark phrases w.r.t. time.
Time information is used to create AudioMediaAssets.

Phrase detector will not be part of core toolkit as discussed earlier. So it can not use under lying wavClip class. As a result we need following function in toolkit to create AudioMediaData according to time markings.
4.1. A function which takes begin time and end time as parameter and returns part AudioMediaData which is actually an extract of larger AudioMediaData which had called  this function.
Remark: the returned AudioMediaData should not share clips with its parent AudioMediaData i.e. it is an individual entity which shares only physical files on disk.


 5. PlayBack.
Playback is mainly dependent on streams which are already provided by toolkit.
In addition playback also need a function to return a small extract of AudioMediaData so function described in 4.1 will be used here.
Remark: Function described in 4.1. will be mostly used to  get a temporary AudioMediaData from existing AudioMediaData so it is not always required to return a managed AudioMediaData. For this it is proposed that Function 4.1. takes a flag as a parameter which determines if returned AudioMediaData is managed or not.

